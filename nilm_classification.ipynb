{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bfe39d8e0e83823",
   "metadata": {},
   "source": [
    "Importy bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3a6c9e826b6f3d93",
   "metadata": {},
   "source": [
    "Wczytanie danych, przetwarzanie i inżynieria cech"
   ]
  },
  {
   "cell_type": "code",
   "id": "5b7064a6ecf29a4b",
   "metadata": {},
   "source": [
    "FILE = 'data/stan_ustalony_gotowe.csv'\n",
    "\n",
    "# Lista cech (bazowa)\n",
    "SELECTED_FEATURES = [\n",
    "    'Active Power 1 (Cycle) [W]',\n",
    "    'Reactive Power 1 (Cycle) [VAr]',\n",
    "    'Power Factor 1 (Cycle) (Load)',\n",
    "    'RMS - non-Fundamental I1 (Cycle) [A]',\n",
    "    'Voltage and Current - Harmonics Amplitude I1 Harmonic 3 (Cycle) [A]',\n",
    "    'Voltage and Current - Harmonics Amplitude I1 Harmonic 5 (Cycle) [A]',\n",
    "    'Active Power - per Harmonic 1 Harmonic 3 (Cycle) [W]',\n",
    "]\n",
    "\n",
    "# Lista wszystkich urządzeń/klas\n",
    "DEVICE_COLUMNS = [\n",
    "    'kettle', 'induction_cooker', 'phone_charger', 'microwave', 'mixer',\n",
    "    'toaster', 'tv', 'spin_dryer', 'coffee_maker', 'immersion_heater',\n",
    "    'sandwich_maker', 'decoder', 'lamp', 'aquarium', 'heater',\n",
    "    'usb_c_charger', 'laptop', 'christmas_tree', 'timer', 'hair_straightener',\n",
    "    'fridge', 'printer', 'bathroom_heater', 'Monitor'\n",
    "]\n",
    "\n",
    "# Wczytanie surowych danych\n",
    "df = pd.read_csv(FILE, sep=';', decimal=',')\n",
    "df = df.iloc[:, :120]\n",
    "# Funkcja czyszcząca wartości Power Factor (usuwanie 'CAP'/'IND')\n",
    "def clean_power_factor(value):\n",
    "    if isinstance(value, str):\n",
    "        value = value.replace(' CAP', '').replace(' IND', '').strip()\n",
    "        value = value.replace(',', '.')\n",
    "    return value\n",
    "\n",
    "# Czyszczenie kolumn Power Factor\n",
    "PF_COLS = [col for col in SELECTED_FEATURES if 'Power Factor' in col]\n",
    "for col in PF_COLS:\n",
    "    df[col] = df[col].apply(clean_power_factor)\n",
    "\n",
    "# Konwersja cech na typ numeryczny\n",
    "for col in SELECTED_FEATURES:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Weryfikacja liczby wierszy przed czyszczeniem\n",
    "print(f\"Liczba wierszy przed czyszczeniem: {len(df)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Definicje nazw kolumn (niezbędne do obliczeń)\n",
    "col_v = 'RMS V1N (Cycle) [V]'\n",
    "col_i = 'RMS I1 (Cycle) [A]'\n",
    "col_p = 'Active Power 1 (Cycle) [W]'\n",
    "col_q = 'Reactive Power 1 (Cycle) [VAr]'\n",
    "\n",
    "# Upewniamy się, że kolumny są numeryczne (dla bezpieczeństwa)\n",
    "for col in [col_v, col_i, col_p, col_q]:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Obliczenie całkowitej mocy pozornej (S) - baza dla obu teorii\n",
    "df['S_total_calc'] = df[col_v] * df[col_i]\n",
    "\n",
    "# 1. Teoria Budeanu (Twoja dotychczasowa cecha)\n",
    "# Wzór: D = sqrt(S^2 - P^2 - Q^2)\n",
    "term_under_sqrt = (df['S_total_calc']**2) - (df[col_p]**2) - (df[col_q]**2)\n",
    "df['Budeanu Distortion Power [VAr]'] = np.sqrt(np.maximum(term_under_sqrt, 0))\n",
    "\n",
    "# 2. Teoria Fryzego\n",
    "\n",
    "\n",
    "# A. Konduktancja Czynna (Gw)\n",
    "# Wzór: Gw = P / U^2\n",
    "df['Fryze_Conductance'] = df[col_p] / (df[col_v] ** 2)\n",
    "\n",
    "# B. Prąd Czynny Fryzego (Iw)\n",
    "# Wzór: Iw = Gw * U  (zastosowanie konduktancji do wzoru na prąd)\n",
    "df['Fryze_Active_Current'] = df['Fryze_Conductance'] * df[col_v]\n",
    "\n",
    "# C. Prąd Bierny Fryzego (Ib)\n",
    "# Wzór: Ib = sqrt(I_calkowite^2 - Iw^2)\n",
    "\n",
    "df['Fryze_Passive_Current'] = np.sqrt(np.maximum(df[col_i]**2 - df['Fryze_Active_Current']**2, 0))\n",
    "\n",
    "# D. Moc Bierna Fryzego (Pb)\n",
    "# Wzór: Pb = sqrt(S^2 - P^2)\n",
    "df['Fryze_Passive_Power'] = np.sqrt(np.maximum(df['S_total_calc']**2 - df[col_p]**2, 0))\n",
    "\n",
    "# 3. Aktualizacja listy cech wejściowych do modelu\n",
    "NEW_FEATURES = [\n",
    "    'Budeanu Distortion Power [VAr]',\n",
    "    'Fryze_Conductance',\n",
    "    'Fryze_Active_Current',\n",
    "    'Fryze_Passive_Current',\n",
    "    'Fryze_Passive_Power'\n",
    "]\n",
    "\n",
    "# Dodaanie nowych cech do listy wybranych cech\n",
    "for feature in NEW_FEATURES:\n",
    "    if feature not in SELECTED_FEATURES:\n",
    "        SELECTED_FEATURES.append(feature)\n",
    "        print(f\"-> Dodano nową cechę: {feature}\")\n",
    "\n",
    "print(f\"\\nLiczba cech: {len(SELECTED_FEATURES)}\")\n",
    "print(SELECTED_FEATURES)"
   ],
   "id": "5f94e2f109376ead"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1. Zastępujemy wartości Inf/ -Inf NaN\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# 2. Zastępujemy wartości NaN zerami w wybranych cechach\n",
    "df[SELECTED_FEATURES] = df[SELECTED_FEATURES].fillna(0)\n",
    "\n",
    "print(f\"Wartości NaN/Inf zastąpiono zerami.\")\n",
    "print(f\"Liczba wierszy: {len(df)}\")\n",
    "\n",
    "if len(df) == 0:\n",
    "    raise ValueError(\"Zbiór danych jest pusty\")\n",
    "\n",
    "# Przygotowanie macierzy cech (X) i etykiet (y)\n",
    "for col in DEVICE_COLUMNS:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "X = df[SELECTED_FEATURES].values\n",
    "y = df[DEVICE_COLUMNS].values\n",
    "\n",
    "# Podział na zbiory treningowe/testowe i standaryzacja\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Wymiary X_train: {X_train_scaled.shape}, wymiary y_train: {y_train.shape}\")\n",
    "print(f\"Liczba cech: {len(SELECTED_FEATURES)}\")\n",
    "print(SELECTED_FEATURES)"
   ],
   "id": "2c6914d830999133"
  },
  {
   "cell_type": "markdown",
   "id": "95ad136652eb036",
   "metadata": {},
   "source": [
    "Analiza rozkładu klas (urządzeń) w zbiorach treningowych i testowych"
   ]
  },
  {
   "cell_type": "code",
   "id": "f5d9833ecfeebfa6",
   "metadata": {},
   "source": [
    "# Zliczanie aktywności urządzeń w zbiorach\n",
    "train_counts = y_train.sum(axis=0)\n",
    "test_counts = y_test.sum(axis=0)\n",
    "total_counts = train_counts + test_counts\n",
    "\n",
    "# Utworzenie ramki danych z podsumowaniem\n",
    "distribution_df = pd.DataFrame({\n",
    "    'Device': DEVICE_COLUMNS,\n",
    "    'Train (1s)': train_counts,\n",
    "    'Test (1s)': test_counts,\n",
    "    'Total (1s)': total_counts,\n",
    "    'Share [%]': (total_counts / len(df) * 100).round(2)\n",
    "})\n",
    "\n",
    "# Sortowanie malejąco wg liczby wystąpień\n",
    "distribution_df.sort_values(by='Total (1s)', ascending=False, inplace=True)\n",
    "\n",
    "print(\"Szczegółowy rozkład aktywności urządzeń:\")\n",
    "try:\n",
    "    display(distribution_df)\n",
    "except NameError:\n",
    "    print(distribution_df)\n",
    "\n",
    "# Weryfikacja występowania pustych klas\n",
    "zero_classes = distribution_df[distribution_df['Total (1s)'] == 0]['Device'].tolist()\n",
    "if zero_classes:\n",
    "    print(f\"\\nBrak próbek pozytywnych dla: {zero_classes}\")\n",
    "else:\n",
    "    print(\"\\nWszystkie urządzenia posiadają reprezentację w danych.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "206bc56a245a331a",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "id": "15e4e5e7dae6d5c6",
   "metadata": {},
   "source": [
    "# Konfiguracja modelu\n",
    "#rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=320,        # większa liczba drzew\n",
    "    max_depth=25,            # zmniejszona glebokosc\n",
    "    min_samples_split=5,     # wezel musi miec min 5 probek do podzialu\n",
    "    min_samples_leaf=2,      # lisc min 2 probki\n",
    "    class_weight='balanced', # wieksze wagi dla mniejszościowych klas\n",
    "    n_jobs=-1,               # Użycie wszystkich rdzeni CPU\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Dopasowanie modelu do danych treningowych\n",
    "print(\"Rozpoczynam trening Random Forest...\")\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "print(\"Trening zakończony.\")\n",
    "\n",
    "# Predykcja na zbiorze testowym\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Obliczenie dokładności (Exact Match Ratio)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nDokładność całkowita (Exact Match): {acc:.2%}\\n\")\n",
    "\n",
    "# Generowanie raportu klasyfikacji\n",
    "print(\"Raport klasyfikacji:\")\n",
    "print(classification_report(y_test, y_pred, target_names=DEVICE_COLUMNS, zero_division=0))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2b2d4068279b7049",
   "metadata": {},
   "source": [
    "Deep Neural Network (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "id": "8a596ba12182c07b",
   "metadata": {},
   "source": [
    "# Sprawdzenie dostępności GPU\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Dostępne urządzenia: {tf.config.list_physical_devices()}\")\n",
    "\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "output_dim = y_train.shape[1]  # Liczba urządzeń (klas)\n",
    "\n",
    "model = models.Sequential([\n",
    "    # Warstwa wejściowa -> Ukryta 1\n",
    "    layers.Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "    layers.Dropout(0.3),  # Zapobiega overfittingowi\n",
    "    \n",
    "    # Ukryta 1 -> Ukryta 2\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    # Warstwa wyjściowa\n",
    "    layers.Dense(output_dim)\n",
    "])\n",
    "\n",
    "# Wyświetlenie podsumowania architektury\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    # from_logits=True to odpowiednik BCEWithLogitsLoss\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(\"Rozpoczynam trening sieci neuronowej (TensorFlow)...\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Wykres funkcji straty\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Przebieg uczenia (Loss)')\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('Loss (BCE)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Predykcja zwraca \"logits\" (surowe wartości)\n",
    "logits = model.predict(X_test_scaled)\n",
    "\n",
    "# Konwersja logits -> prawdopodobieństwa (Sigmoid)\n",
    "probs = tf.nn.sigmoid(logits).numpy()\n",
    "\n",
    "# Binaryzacja wyników (Próg 0.5)\n",
    "y_pred_numpy = (probs > 0.5).astype(int)\n",
    "\n",
    "# Raport wyników\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "acc_dnn = accuracy_score(y_test, y_pred_numpy)\n",
    "\n",
    "print(f\"\\nDokładność DNN (Exact Match): {acc_dnn:.2%}\")\n",
    "print(\"Szczegółowy raport klasyfikacji:\")\n",
    "print(classification_report(y_test, y_pred_numpy, target_names=DEVICE_COLUMNS, zero_division=0))"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
